{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d8e1590-21cc-41f4-8276-97e383455588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c79c5520-b6aa-46e0-8a8e-2a3680705509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "\n",
    "    if x > 100:\n",
    "        sigm = 1.\n",
    "    elif x < -100:\n",
    "        sigm = 0.\n",
    "    else:\n",
    "        sigm = 1. / (1. + np.exp(-x))\n",
    "\n",
    "    if derivative:\n",
    "        return sigm * (1. - sigm)\n",
    "    return sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f7f52b2-a39f-4424-92ba-c585dc44315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(data, skill_dim, concept_dim, lambda_s, lambda_t,\n",
    "           penalty_weight, tol=1e-3, trade_off_example=0.1, max_iter=40, lr=0.005):\n",
    "\n",
    "    config = {\n",
    "        'num_users': data['num_users'],\n",
    "        'num_questions': data['num_quizs'],\n",
    "        'num_discussions': data['num_disicussions'],\n",
    "        'num_attempts': data['num_attempts'],\n",
    "        'num_skills': skill_dim,\n",
    "        'num_concepts': concept_dim,\n",
    "        'lambda_s': lambda_s,\n",
    "        'lambda_t': lambda_t,\n",
    "        'penalty_weight': penalty_weight,\n",
    "        'trade_off_example': trade_off_example,\n",
    "        'lr': lr,\n",
    "        'tol': tol,\n",
    "        'max_iter': max_iter,\n",
    "    }\n",
    "\n",
    "    train_set = []\n",
    "    for (stud, ques, obs, att, res) in data['train']:\n",
    "        train_set.append((int(stud), int(att), int(ques), float(obs), int(res)))\n",
    "    config['train'] = train_set\n",
    "\n",
    "    test_set = []\n",
    "    for (stud, ques, obs, att, res) in data['test']:\n",
    "        if int(att) < 100:\n",
    "            test_set.append((int(stud), int(att), int(ques), float(obs), int(res)))\n",
    "    \n",
    "    config['num_attempts'] = 19\n",
    "    config['test'] = test_set\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea1175a8-095d-4bf8-a4f7-64f7de2975f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE: 0.2379254225855171\n",
      "\n",
      "MAE: 0.17730242741580224\n",
      "\n",
      "Termino satisfactoriamente....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-------------------------------------- Hiperparametros -------------------------------------------------\n",
    "\n",
    "skill_dim = 3\n",
    "concept_dim = 5\n",
    "lambda_s = 0\n",
    "lambda_t = 0\n",
    "penalty_weight = 0.01\n",
    "lr = 0.005\n",
    "max_iter = 40 \n",
    "trade_off_example = 0.1\n",
    "tol = 1e-3\n",
    "\n",
    "\n",
    "#----------------------------------- Lectura de la Data ----------------------------------------------\n",
    "\n",
    "dataRN = pd.read_csv('Datos.csv')\n",
    "\n",
    "\n",
    "dataRN = dataRN.sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "data_train = []\n",
    "for (i, j, k, l, m) in dataRN.values:\n",
    "    data_train.append([i, j, k, l, m])\n",
    "\n",
    "data_test = data_train[:int(len(data_train) * 0.2)]\n",
    "for x in data_test:\n",
    "    data_train.remove(x)\n",
    "\n",
    "data = {}\n",
    "\n",
    "data['num_users'] = 17\n",
    "data['num_quizs'] = 12 \n",
    "data['num_disicussions'] = 8\n",
    "data['num_attempts'] = 19\n",
    "data['train'] = data_train\n",
    "data['test'] = data_test\n",
    "\n",
    "\n",
    "#-------------------------------- Asignacion del diccionario config ---------------------------------\n",
    "\n",
    "model_config = config(data, skill_dim, concept_dim, lambda_s, lambda_t,\n",
    "                          penalty_weight, lr=lr, max_iter=max_iter, trade_off_example=trade_off_example)\n",
    "\n",
    "\n",
    "#------------------------------------ Inicializacion de matrices y variables-------------------------------\n",
    "\n",
    "test_set = model_config['test']\n",
    "train_data = model_config['train']\n",
    "num_users = model_config['num_users']\n",
    "num_skills = model_config['num_skills']\n",
    "num_attempts = model_config['num_attempts']\n",
    "num_concepts = model_config['num_concepts']\n",
    "num_questions = model_config['num_questions']\n",
    "lambda_s = model_config['lambda_s']\n",
    "lambda_t = model_config['lambda_t']\n",
    "penalty_weight = model_config['penalty_weight']\n",
    "lr = model_config['lr']\n",
    "tol = model_config['tol']\n",
    "max_iter = model_config['max_iter']\n",
    "\n",
    "num_examples = model_config['num_discussions']\n",
    "trade_off_e = model_config['trade_off_example']\n",
    "\n",
    "binarized_example = True\n",
    "\n",
    "loss_list = []\n",
    "val_data = []\n",
    "\n",
    "S = np.random.random_sample((num_users, num_skills))\n",
    "T = np.random.random_sample((num_skills, num_attempts,num_concepts))\n",
    "Q = np.random.random_sample((num_concepts, num_questions)) # Materiales evaluados\n",
    "E = np.random.random_sample((num_concepts, num_examples))  # Materiales no evaluados\n",
    "\n",
    "total_test_count = 0\n",
    "sum_square_error, sum_abs_error = [0.] * 2\n",
    "\n",
    "\n",
    "#---------------------------------- Entrenamiento -------------------------------------------------\n",
    "\n",
    "for ciclo in range(0, 30): \n",
    "    \n",
    "    lr = lr\n",
    "\n",
    "    train_question = [] \n",
    "    for student, attempt, question, obs, resource in train_data:\n",
    "        if resource == 0:\n",
    "            train_question.append((student, attempt, question, obs, resource))\n",
    "\n",
    "    np.random.shuffle(train_question)\n",
    "    \n",
    "    val_data = train_question[:int(len(train_question) * 0.2)]  # se toma el 20% para data de validacion, esta data cambia\n",
    "    train_question_size = len(train_question) - len(val_data)   # por cada iteracion\n",
    "    \n",
    "    for record in val_data:\n",
    "        try:\n",
    "            train_data.remove(record)\n",
    "        except:\n",
    "            print(record)\n",
    "            print(record in val_data)\n",
    "            print(record in train_data)\n",
    "            print(sorted(train_data, key=lambda x:x[1]))\n",
    "\n",
    "\n",
    "    iter = 0\n",
    "    val_q_rmse_list = [1.]\n",
    "    converge = False\n",
    "    min_iters = 35\n",
    "\n",
    "\n",
    "    while not converge:\n",
    "\n",
    "        np.random.shuffle(train_data)\n",
    "\n",
    "        if iter > 0:\n",
    "            S = best_S\n",
    "            Q = best_Q\n",
    "            T = best_T\n",
    "            E = best_E\n",
    "    \n",
    "        for (student, attempt, index, obs, resource) in train_data:\n",
    "            \n",
    "            # ----------- Paso de actualizacion de Q\n",
    "            if resource == 0:\n",
    "            \n",
    "                grad_q = np.zeros_like(Q[:, index])\n",
    "                if obs != None:\n",
    "\n",
    "                    pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), Q[:, index])\n",
    "                    grad_q = -2. * (obs - pred) * np.dot(S[student, :], T[:, attempt, :])\n",
    "\n",
    "                Q[:, index] -= lr * grad_q\n",
    "                Q[:, index][Q[:, index] < 0.] = 0.\n",
    "\n",
    "                sum = np.sum(Q[:, index])\n",
    "                if sum != 0:\n",
    "                    Q[:, index] /= sum\n",
    "            \n",
    "            # ----------- Paso de actualizacion de E\n",
    "            elif resource == 1:\n",
    "\n",
    "                grad_e = np.zeros_like(E[:, index])\n",
    "                if obs != None:\n",
    "                    pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), E[:, index])\n",
    "\n",
    "                    if binarized_example:\n",
    "                        grad_e = -2. * trade_off_e * (obs - pred) * pred * (1. - pred) * np.dot(\n",
    "                            S[student, :], T[:, attempt, :])\n",
    "                    else:\n",
    "                        grad_e = -2. * trade_off_e * (obs - pred) * np.dot(S[student, :],\n",
    "                                                                            T[:, attempt, :])\n",
    "\n",
    "                E[:, index] -= lr * grad_e\n",
    "                E[:, index][E[:, index] < 0.] = 0.\n",
    "\n",
    "                sum = np.sum(E[:, index])\n",
    "                if sum != 0:\n",
    "                    E[:, index] /= sum \n",
    "\n",
    "    \n",
    "            # ----------- Paso de actualizacion de S\n",
    "            grad_s = np.zeros_like(S[student, :])\n",
    "            if obs != None:\n",
    "                if resource == 0:\n",
    "\n",
    "                    pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), Q[:, index])\n",
    "\n",
    "                    grad_s = -2. * (obs - pred) * np.dot(T[:, attempt, :], Q[:, index])\n",
    "\n",
    "                elif resource == 1:\n",
    "                    \n",
    "                    pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), E[:, index])\n",
    "\n",
    "                    if binarized_example:\n",
    "                        grad_s = -2. * trade_off_e * (obs - pred) * pred * (1. - pred) * np.dot(\n",
    "                            T[:, attempt, :], E[:, index])\n",
    "                    else:\n",
    "                        grad_s = -2. * trade_off_e * (obs - pred) * np.dot(T[:, attempt, :],\n",
    "                                                                                E[:, index])\n",
    "            grad_s += 2. * lambda_s * S[student, :]\n",
    "\n",
    "\n",
    "            S[student, :] -= lr * grad_s\n",
    "\n",
    "            if lambda_s == 0.:\n",
    "                S[student, :][S[student, :] < 0.] = 0.\n",
    "                sum = np.sum(S[student, :])\n",
    "\n",
    "            if sum != 0:\n",
    "                S[student, :] /= sum\n",
    "\n",
    "            # ----------- Paso de actualizacion de T\n",
    "            grad_t = np.zeros_like(T[:, attempt, :])\n",
    "            if obs != None:\n",
    "                \n",
    "                if resource == 0:\n",
    "                    pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), Q[:, index])\n",
    "\n",
    "                    grad_t = -2. * (obs - pred) * np.outer(S[student, :], Q[:, index])\n",
    "\n",
    "                elif resource == 1:\n",
    "\n",
    "                    pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), E[:, index])\n",
    "\n",
    "                    if binarized_example:\n",
    "                        grad_t = -2. * trade_off_e * (obs - pred) * pred * (1. - pred) * np.outer(\n",
    "                            S[student, :],\n",
    "                            E[:, index])\n",
    "                    else:\n",
    "                        grad_t = -2. * trade_off_e * (obs - pred) * np.outer(S[student, :],\n",
    "                                                                                E[:, index])\n",
    "            grad_t += 2. * lambda_t * T[:, attempt, :]\n",
    "\n",
    "            if resource == 0:\n",
    "                if attempt == 0:\n",
    "                    diff = T[:, attempt + 1, :] - T[:, attempt, :]\n",
    "                    diff[diff > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    diff[diff < 0.] = -1.\n",
    "                    grad_t -= penalty_weight * diff\n",
    "                        \n",
    "                elif attempt == num_attempts - 1:\n",
    "                    gap = T[:, attempt, :] - T[:, attempt - 1, :]\n",
    "                    gap[gap > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    gap[gap < 0.] = 1.\n",
    "                    grad_t -= penalty_weight * gap\n",
    "                    \n",
    "                else:\n",
    "                    diff = T[:, attempt, :] - T[:, attempt - 1, :]\n",
    "                    diff[diff > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    diff[diff < 0.] = 1.\n",
    "                    grad_t -= penalty_weight * diff\n",
    "                    \n",
    "\n",
    "                    diff = T[:, attempt + 1, :] - T[:, attempt, :]\n",
    "                    diff[diff > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    diff[diff < 0.] = -1.\n",
    "\n",
    "            elif resource == 1:\n",
    "                if attempt == 0:\n",
    "                    diff = T[:, attempt + 1, :] - T[:, attempt, :]\n",
    "                    diff[diff > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    diff[diff < 0.] = -1.\n",
    "                    grad_t -= penalty_weight * diff\n",
    "                    \n",
    "                    \n",
    "                elif attempt == num_attempts - 1:\n",
    "                    diff = T[:, attempt, :] - T[:, attempt - 1, :]\n",
    "                    diff[diff > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    diff[diff < 0.] = 1.\n",
    "                    grad_t -= penalty_weight * diff\n",
    "\n",
    "                else:\n",
    "                    diff = T[:, attempt, :] - T[:, attempt - 1, :]\n",
    "                    diff[diff > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    diff[diff < 0.] = 1.\n",
    "                    grad_t -= penalty_weight * diff\n",
    "\n",
    "                    diff = T[:, attempt + 1, :] - T[:, attempt, :]\n",
    "                    diff[diff > 0.] = 0.\n",
    "\n",
    "                    # Penalizacion\n",
    "                    diff[diff < 0.] = -1.\n",
    "                    grad_t -= penalty_weight * diff\n",
    "\n",
    "            T[:, attempt, :] -= lr * grad_t\n",
    "\n",
    "\n",
    "        #----------- Calculo de la funcion de costo\n",
    "        \n",
    "        #----- L1\n",
    "        loss, square_loss = 0., 0.\n",
    "        square_loss_q, square_loss_l, square_loss_e = 0., 0., 0.\n",
    "        q_count, l_count, e_count = 0., 0., 0.\n",
    "\n",
    "        for (student, attempt, question, obs, resource) in train_data:\n",
    "            \n",
    "            if resource == 0:\n",
    "\n",
    "                \"\"\"\n",
    "                    Se hace le producto matricial entre S y T y luego con Q\n",
    "                    En la matriz S tomamos la que corresponde al estudiante student\n",
    "                    En la matriz T tomamos de cada capa el intento attempt\n",
    "                    En la matriz Q tomamos la columna question de cada concepto\n",
    "                \"\"\"\n",
    "                pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), Q[:, question])\n",
    "\n",
    "                square_loss_q += (obs - pred) ** 2\n",
    "            \n",
    "                q_count += 1\n",
    "\n",
    "            elif resource == 1:\n",
    "            \n",
    "                pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), E[:, question])\n",
    "\n",
    "                if binarized_example:\n",
    "                    pred = sigmoid(pred)\n",
    "\n",
    "                square_loss_e += (obs - pred) ** 2\n",
    "                e_count += 1\n",
    "\n",
    "        square_loss = square_loss_q + trade_off_e * square_loss_e\n",
    "\n",
    "        \"\"\"\n",
    "            Ahora calculamos el error de las regularizaciones\n",
    "            Aplicamos regularizacion a S y T\n",
    "        \"\"\"\n",
    "\n",
    "        reg_S = LA.norm(S) ** 2  # norma 2\n",
    "        reg_T = LA.norm(T) ** 2  # norma 2\n",
    "\n",
    "        reg_loss = lambda_s * reg_S + lambda_t * reg_T\n",
    "        \n",
    "        loss = square_loss + reg_loss\n",
    "\n",
    "        q_rmse = np.sqrt(square_loss_q / q_count) if q_count != 0 else 0. \n",
    "        e_rmse = np.sqrt(trade_off_e * square_loss_e / e_count) if e_count != 0 else 0.\n",
    "\n",
    "        # --- Penalizacion dada por L2            \n",
    "        penalty = 0.\n",
    "        for (student, attempt, index, obs, resource) in train_data:\n",
    "            if attempt >= 1:\n",
    "                gap = T[:, attempt, :] - T[:, attempt - 1, :] \n",
    "                gap[gap > 0.] = 0. \n",
    "                if resource == 0:   \n",
    "                    diff = np.dot(np.dot(S[student, :], gap), Q[:, index])\n",
    "                elif resource == 1:                                       \n",
    "                    diff = np.dot(np.dot(S[student, :], gap), E[:, index])\n",
    "            \n",
    "                penalty -= penalty_weight * diff\n",
    "                \n",
    "        loss += penalty\n",
    "\n",
    "        #------- Termina la funcion de costo\n",
    "\n",
    "        \"\"\"\n",
    "        La data de validacion en cada iteracion es tomada\n",
    "        de forma aleatoria. Esta data solo contiene materiales del tipo evaluado (resource = 0).\n",
    "        Ademas utiliza las matrices S, T, Q y E optimizadas\n",
    "        ya que pasaron por el proceso del descenso de gradiente estocastico.\n",
    "        Por lo tanto, siempre tenemos distintos errores\n",
    "        \"\"\"\n",
    "        \n",
    "        val_q_count, val_q_rmse, abs_error = [0.] * 3\n",
    "\n",
    "        for (student, attempt, question, obs, resource) in val_data: \n",
    "            if resource == 0:\n",
    "                \n",
    "                val_q_count += 1.\n",
    "                \n",
    "                pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), Q[:, question])\n",
    "     \n",
    "                val_q_rmse += (obs - pred) ** 2\n",
    "                abs_error += abs(obs - pred)\n",
    "\n",
    "        if val_q_count == 0:\n",
    "            val_q_count, val_q_rmse, abs_error = [0.] * 3\n",
    "        else:\n",
    "            val_q_rmse = np.sqrt(val_q_rmse / val_q_count)\n",
    "            mae = abs_error / val_q_count\n",
    "\n",
    "        #------------------    \n",
    "\n",
    "        # Criterios de Parada\n",
    "        if iter == max_iter:\n",
    "            loss_list.append(loss)\n",
    "            converge = True\n",
    "            count_max_iter += 1\n",
    "\n",
    "        elif iter >= min_iters and abs(val_q_rmse - val_q_rmse_list[-1]) < tol:\n",
    "            loss_list.append(loss)\n",
    "            converge = True\n",
    " \n",
    "        elif iter >= min_iters and val_q_rmse >= np.mean(val_q_rmse_list[-3:]):\n",
    "            converge = True\n",
    "         \n",
    "        elif iter >= min_iters and loss >= np.mean(loss_list[-3:]):\n",
    "            converge = True\n",
    "\n",
    "        elif val_q_rmse >= val_q_rmse_list[-1]:\n",
    "            loss_list.append(loss)\n",
    "            val_q_rmse_list.append(val_q_rmse)\n",
    "            iter += 1                           \n",
    "\n",
    "        else:\n",
    "            loss_list.append(loss)\n",
    "            val_q_rmse_list.append(val_q_rmse)\n",
    "            iter += 1\n",
    "\n",
    "        best_S = S\n",
    "        best_T = T\n",
    "        best_Q = Q\n",
    "        best_E = E\n",
    "\n",
    "    for record in val_data:  # Estamos fuera del While. La data que quitamos de entreno la volvemos a colocar\n",
    "        train_data.append(record)\n",
    "        \n",
    "        #--------------- Termina training() -----------------\n",
    "\n",
    "\n",
    "#-------------------------- testing() --------------------------\n",
    "\n",
    "    val_q_count, val_q_rmse, abs_error = [0.] * 3\n",
    "\n",
    "    for (student, attempt, question, obs, resource) in test_set:\n",
    "        if resource == 0:\n",
    "\n",
    "            val_q_count += 1.\n",
    "            \n",
    "            pred = np.dot(np.dot(S[student, :], T[:, attempt, :]), Q[:, question])\n",
    "    \n",
    "            val_q_rmse += (obs - pred) ** 2\n",
    "            abs_error += abs(obs - pred)\n",
    "\n",
    "    if val_q_count == 0:\n",
    "        val_q_count, val_q_rmse, abs_error = [0.] * 3\n",
    "    else:\n",
    "        val_q_rmse = np.sqrt(val_q_rmse / val_q_count)\n",
    "        mae = abs_error / val_q_count\n",
    "        \n",
    "    test_count, _rmse, _mae = val_q_count, val_q_rmse, mae\n",
    "\n",
    "    sum_square_error += (_rmse ** 2) * test_count # esto es solo suma((obs - pred) ** 2)\n",
    "    sum_abs_error += _mae * test_count\n",
    "    total_test_count += test_count\n",
    "\n",
    "\n",
    "rmse = np.sqrt(sum_square_error / total_test_count) # root mean square error datos de testing\n",
    "mae = sum_abs_error / total_test_count  # mean absolute error datos de test\n",
    "\n",
    "print(f'\\nRMSE: {rmse}')\n",
    "print(f'\\nMAE: {mae}')\n",
    "\n",
    "print('\\nTermino satisfactoriamente....\\n')\n",
    "\n",
    "S = best_S\n",
    "Q = best_Q\n",
    "T = best_T\n",
    "E = best_E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
